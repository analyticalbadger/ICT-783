{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data and Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train,y_train), (x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1468fb76f98>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What does the data look like?\n",
    "plt.imshow(x_train[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)/255\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sheldon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Input Layer - 2-D convolutional layer\n",
    "model.add(Conv2D(28,(3,3),input_shape=(28,28,1),activation='relu'))\n",
    "# First Hidden Layer - 2-D max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Second Hidden Layer - flattening layer\n",
    "model.add(Flatten())\n",
    "# Third Hidden Layer - fully-connected layer\n",
    "model.add(Dense(units=128,activation='relu'))\n",
    "# Output Layer - fully-connected layer\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sheldon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.1525 - acc: 0.9544TA: 1:34 - loss: 0.7950 - acc: 0.770 - ETA: 1:34 - loss: 0.7855 - acc:  - ETA: 1:32 - loss: 0.7286 - acc:  - ETA: 1:30 - loss: 0.6855 - acc - ETA: 1:29 - loss: 0.64 - ETA: 1:26 - loss: 0.5808 - acc:  - ETA: 1:26 - loss: 0.5626 - acc: 0.83 - ETA: 1:25 - loss: 0.5541 - a - ETA: 1:24 - loss:  - ETA: 1:10 - loss: 0.3444 - acc - ETA: 1:09 - loss: 0.3389 - acc: 0.9 - ETA: 1:09 - los - ETA: 1:07 - loss: 0.31 - ETA: 1:05 - loss: 0.3062 - acc: 0 - ETA: 1:05 - loss: 0.3032 - acc: 0.911 - ETA: 1:05 - loss: 0.3025 - acc: - ETA: 1:04 - loss: 0.2994 -  - ETA: 1:03 - loss: 0.2934  - ETA: 1:02 - loss: 0.2882 - acc: 0.91 - ETA: 1:02 - loss: 0.2875 - a - ETA:  - ETA: 59 - ETA: 26s - loss: 0.1825 - acc:  - ETA: 25s -  - ETA - ETA: 17s -  - ETA: 14s - loss: 0.1672 - acc: 0.94 - ETA: 14s - l - ETA: 8s - loss: 0.159 - ETA: 6s - loss: 0.1582 - acc: 0.952 - ETA: 6s - loss: 0.1581 - acc:  - ETA: 6s - - - ETA: 1s - loss:\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0531 - acc: 0.9835: 13s - loss: 0.0527 - acc: 0. - ETA: 13s - loss: 0.0527 - ETA: 13s  - ETA:  - ETA: 8s - loss: 0.0531 - acc: - ETA: 8s - loss: 0.0531 - a - ETA: 7s - loss: 0.0530 - acc:  - ETA: 6s - loss: 0.0530 - acc: 0.98 - ETA: 6s - loss: 0.0530 - a - ETA: 5s - loss: 0.0530 - - ETA: 4s - loss: 0.0528 - acc: 0. - ETA: 4 - ETA: 1s - l\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0342 - acc: 0.9895  - ETA: 1:22 - loss: 0.0259 - acc: 0. - ETA: 1:22 - loss: 0.0256 - acc: 0.99 - ETA: 1:22 - loss: 0.0276 - acc: 0.99 - ETA: 1:21 - loss: 0.0272 - acc: 0.991 - - ETA: 1:12 - loss: 0.0286 - ETA: 1:11 - loss: 0.0288 - a - ETA: 1:10 - loss: 0.0288 - acc: 0.9 - - ETA - ETA: 1:04 - loss: 0.0287 - - ETA: 1:03 - loss: 0.0290 - acc: 0. - ETA: 1:03 - loss: 0.0290 - acc: 0.99 - ETA: 1:03 - loss: 0.0291 - acc - ETA: 1:02 - loss: 0.0297  -  - ETA: 59s - loss: 0.0302 - - ETA: 56s - loss: 0.0304 - acc: 0.99 - ETA: 56s - loss: 0.03 - ETA: 55s - loss: 0.0307 - acc:  - ETA: 55s  - ETA: 51s - loss: 0.03 - ETA: 50s - loss: 0.0314 - acc:  - ETA: 50s - loss: 0. - ETA: 49s - loss: 0.0316 - ETA: 48s - loss: 0.0317 - - ETA: 48s - loss: 0.0317 - acc:  - ETA: 44s - loss: 0.0327 - - ETA: 43s - loss: 0.0328 - acc: 0. - ETA: 43s - loss: 0. - ETA: 42s - loss: 0.0325 - acc: 0.98 - ETA: 42s  - E - ETA: 22s - loss: 0.0324 - ETA: 17s - loss - - ETA: 11s - loss: 0.0335 -  - ETA: 8s - loss: 0.0336 - acc - ETA:  - ETA: 1s - loss: 0.0342 -  - ETA: 1s - loss: 0.0342 - ac - ETA: 0s - loss: 0.0341 - acc: 0. - 88s 1ms/step - loss: 0.0342 - acc: 0.9895\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0220 - acc: 0.9931T - ETA: 1:22 - loss: 0.0228 - acc: 0.993 - ETA: 1:22 - loss: 0.0224 - acc: 0.9 - ETA: 1:22 - loss: 0.0220 - acc:  - ETA: 1:22 - loss: 0 - ETA: 1:20 - loss: 0.0206 - acc: 0.993 - ETA: 1:20 - loss: 0.0206 - acc: 0.9 - ET - ETA: 1:18 - loss: 0.0203 - acc: 0. - ETA: 1:17 - loss: 0.0201 - ac - ETA: 1:17 - loss: 0.0199 - acc: 0 - ETA: 1:16 - loss: 0. - ETA: 1:15 - loss: 0.0202 - acc: 0.99 - ETA: 1:15 - loss: 0.0200 - acc: 0.99 - ETA: 1:15 - loss: 0.0200 - acc: 0.99 - ETA: 1:14 - loss: 0.0198 - acc - ETA: 1:14 - loss: 0.0194 - ac - ETA: 1:13 - loss: 0. - ETA: 1:06 -  - ETA: 1:04 - loss: 0.0174 - acc: 0. - ETA: 1:04 - loss: 0.0176 - acc: 0.99 - ETA: 1:03 - loss: 0.0176 - acc: - ETA: 1:03 - loss: 0.0175 - acc: 0.99 - ETA: 1:03 - loss: 0.0176 -  - ETA: 1:02 - loss: 0.0174 - acc: 0. - ETA: 1:02 - loss: 0.0175 - acc: 0.99 - ETA: 1:01 - loss: 0.0175 - acc: 0.99 - ETA: 1:01 - loss: 0.0176 - acc: - ETA: 1:01 - loss: 0.0179 - acc: 0. - ETA: 1:00 - loss: 0 - ETA: 59s - loss: 0. - ETA: 58s - loss: 0.0185 - ETA: 57s - loss: 0.0186 - acc:  - ETA: 45s - loss: 0.0196 - acc: 0. - ETA: 35s - loss: 0.0205 - acc: 0. - ETA: 35s - loss: 0.0205 - acc: 0. - ETA: 35s - loss: 0. - ETA: 34s - loss: 0.0205 - a - ETA: 34s - loss:  - ETA: 33s - loss: 0.0203 - acc - ETA: 33s - loss: 0. - ETA: 32 - E - ETA: 20s - loss: 0.0204 - - ETA: 19s - loss: 0.0204 - acc: 0. - ETA: 19s - loss: 0.0205 - acc:  - ETA: 19s - loss: 0.0205 - a - ETA: 18s  - ETA:  - ETA: 16s - loss: 0.0207 - acc: 0.99 - ETA: 15s - loss: 0.0207 - - ETA: 15s - loss: 0.02 - ETA: 11s - loss: 0.0210 - a - ETA: 10s - loss: - ETA: 8s - loss: 0.0214 - acc: 0. - ETA: 8s - loss: 0.0215 - acc: 0.99 - ETA: 8s - loss: 0.0215 - acc: 0. - ETA: 7s - loss: 0.0216 - acc: - ETA: 7s - loss: 0.0216 - acc:  - ETA: 6s - loss: 0.0216 - acc: 0. - ETA: 6s - loss: 0.0216 - ac - ET - ETA: 2s - loss: 0.0218 - acc: 0.9 - ETA:  - ETA: 0s - loss: 0.0220 - acc: 0.993\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0139 - acc: 0.9956 ETA: 1:17 - lo - E - ETA: 1:12 - loss: 0.0110 - acc: 0.9 - ETA: 1:12 - loss: 0.0109 - acc: 0 - ETA: 1:12 - loss: 0.0106 - a - ETA: 1:11 - loss: 0.0112 -  - ETA: 1:10 - loss: 0.0112 - acc: 0. - ETA: 1:10 - loss: 0.0112 - - ETA: 1:09 - loss: 0.0111 - acc: - ETA: 1:08 - loss: 0.0110 - acc:  - E - - ETA: 52s - loss: 0.0132 - - ETA: 52s - loss - ETA: 51 - E - ETA: 37s - loss: 0.0126 - acc - ETA: 36s - loss: 0.0127 - acc - ETA: 36s - loss: 0.0127 - acc - ETA: 36s - loss: 0.0127 - acc: 0.99 - ETA: 36s -  - ETA: 35s - loss - ETA: 32s - loss: 0.0127 - acc: 0. - ETA: 32s - loss: 0.0128 - acc - ETA: 32s - loss:  - ETA: 21s - loss: 0.01 - ETA: 20s - loss: 0.0132 - ETA: 11s - loss: 0.01 - ETA: 0s - loss: 0.0137 \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0121 - acc: 0.9960TA: 1:19 - loss - ETA: 1:17 - loss - ETA: 1:16 - loss: 0.0082 - acc - ETA: 1:12 - loss: 0.0084 - acc: 0.9 - ETA: 1:12 - los - ETA: 1:09 - loss: 0.0080 - acc: 0.997 - ETA: 1:09 - loss: 0.0079 - acc: 0.99 - ETA: 1:09 - loss: 0.0079 - acc:  - ETA: 1:09 - loss: 0.0080 - acc: 0.9 - ETA: 1:08 - loss: 0.0079 -  - ETA: 1:07 - loss: 0.0083 - acc - ETA: 1:07 - loss: 0.0082 - acc: 0.9 - ETA: 1:06 - los - ETA: 1:04 - loss: 0.0079 - acc: - ETA: 1 - ETA: 43s - loss: 0.0112 - acc: 0.99 - ETA: 43s - loss: 0.0112 - acc: 0.99 - ETA - ETA: 41s - loss: 0.0115 - acc: 0.99 - ETA: 41s - loss: 0.0115 - - ETA: 26s - loss: 0.0112 - a - ETA: 13s - loss: 0.0113 - ETA: 12s - loss: 0.0113 - acc:  - ETA: 12s - loss: 0.0113 - acc: 0. - ETA: 11s - loss: 0. - ETA: 11s - loss: 0.0112 - acc: 0. - ETA: 1 - ETA: 9s - loss: 0. - ETA: 8s - loss: 0.0116 - acc:  - ETA: 8s  - ETA: 5s - loss: 0.0120 - acc: 0. - ETA: 5s - loss: 0 - ETA: 4s - loss: 0.0121 - acc: 0.996 - ETA: 3s - loss: 0.0120 - acc: 0. - ETA: 3s - loss: 0.0120 - acc - ETA: 2s - loss: 0.0121 - acc: 0.9 - ETA: 2s - loss: 0.012 - ETA: 1s - loss: 0.0121 - acc: 0.99 - ETA: 1s - loss: 0.0121 -\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0085 - acc: 0.9970TA: 1:27 - loss: 0.0107 - acc: 0 - ETA: 1:26 - loss: 0.0058 -  - ETA: 1:25 - loss: 0.0094 - acc - ETA: 1:25 - loss: 0.0103 - acc: 0.9 - ETA: 1:25 - loss: 0.0093 - acc: 0.996 - ETA: 1:25 - loss: 0.0091 - ac - ETA: 1:24 - loss: 0.0114 - - ETA: 1:23 - loss: 0.0 - ETA: 1:22 -  - ETA: 1:20 - loss: 0.0071 - acc: 0.99 - ETA: 1:19 - loss: 0.0070 - acc: 0.99 - ETA: 1:19 - loss: 0.0071 - acc:  - ETA: 1:15 - loss: 0.0065 - acc: 0.997 - ETA: 1:15 - loss: 0.0066 - acc:  - ETA: 1:14 - loss: 0.0063 - acc: 0.9 - ETA: 1:14 - loss: 0.0080 - a - ETA: 1:13 - loss: 0. - ETA: 1:11 - loss: 0.0073 - ac - ETA: 1:11 - loss: 0.0072 - acc: 0.99 - ETA: 1:10 - loss: 0.0072 - acc: 0.998 - ETA:  - ETA: 1:07 - loss: 0.0074 - acc:  - ETA: 1:07 - loss: 0.0074 -  - ETA: 1:06 - loss - ETA: 1:04 - loss: 0 - ETA: 1:02 -  - ETA: 1:00  - ETA: 59s - loss:  - ETA:  - ETA: 54s - loss: 0.0069 - acc:  - ETA: 54s - loss: 0.0069 - acc: 0. - ETA: 52s - loss: 0.0070 - a - ETA: 51s - loss:  - ETA: 50s - loss: 0.0069 - acc: 0. - ETA: 50s - loss: 0.0069 - acc: 0. - ETA: 50s - loss: 0. - ETA: 49s - loss: 0.0069 - - ETA: 49s -  - ETA: 47s - loss: 0.0070 - acc:  - ETA: 47 - ETA: 46s - loss: 0.0074 - ETA: 44s - loss:  - ETA:  - ETA: 39s - loss: 0. - ETA: 35s - loss: 0.00 - ETA: 33s - loss: 0.0075 - acc:  - ETA: 32s - loss: 0.0075 - a - ETA: 27s - loss: 0.0075 - acc:  - ETA: 27 - ETA: 24s - loss: 0.0079 - a - ETA - ETA: 22s - loss: 0.0081 - ETA: 21s - loss: 0.0080 - ETA: 16s - loss: 0. - ETA: 14s - loss: 0. - ETA: 13s - loss: 0.0081 - acc: 0.99 - ETA: 13s - loss:  - ETA: 13s - loss: 0.00 - ETA: 8s - loss: 0.0082  - ETA - ETA: 5s - loss: 0.0081 - acc - ETA: 1s - loss: 0.0083 - ac - ETA: 1s - loss: 0.0083 - acc: 0.997 - ETA: 0s - loss: 0.0084 - acc:  - ETA: 0s - loss: 0.0084 - acc: 0.9 - ETA: 0s - loss: 0.0085 - acc: 0.99\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0064 - acc: 0.9979TA: 1:27 -  - ETA: 1:12 - loss: 0.0081 - ac - ETA: 1:08 - loss: - ETA: 1:03 - l - ETA: 56s - lo - ETA: 53s - loss: 0.0061 - acc: 0.99 - ETA: 15s - loss: 0.0067 - acc: 0. - ETA: 15s - loss: 0.0067 - acc - ETA: 14s - loss: 0.0067 - acc:  - ETA: 14s - loss: 0.0067 - a - ETA: 14s - loss: 0.0067 - ETA: 13s -  - ETA: 6s - loss: 0.0066 - ac - ETA: 5s - loss: 0.0065 - acc: 0.99 - ETA:  - ETA: 2s - loss: 0.0065 - acc: 0. - ETA: 2s - loss: 0.0064 - acc: 0. - ETA: 2s - loss: 0.0064 - acc: 0.99 - ETA:\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0043 - acc: 0.9988TA: 1:29 - loss: 0.0 - ETA: 1:24 - loss: 0.0032 - acc: 0. - ETA: 1:24 - loss: 0.0031 - acc: 0.99 - ETA: 1:24 - loss: 0.0030 - - ETA: 1:22 - lo - ETA: 1:20 - loss: 0.0 - ETA: 1:19 - loss: 0.0032 - acc: 0.99 - ETA: 1:19 - loss: 0.0031 - acc:  - ETA: 1:18 - loss - ETA: 1:16 - loss: 0.0036 - acc: 0. - ETA: 1:16 - loss: - ETA: 1:14 - loss:  - ETA: 1:12 - loss: 0.0035 - acc:  - ETA: 1:11 - loss: 0.00 - ETA: 1:10 - loss: 0.0033 - ac - ETA: 1:09 - loss: 0.0032 - acc: - ETA: 1:08 - loss: 0.0032 - acc: 0.9 - ETA: 1:08 - loss: 0.0032 - acc: 0.99 - ETA: 1:08 - loss: 0.0 - ETA: 1:06 - loss: 0.0034 - acc: 0.9 - ETA: 1:06 - loss: 0.0034 - acc:  - ETA: 1 - ETA: 1:03 - loss: 0.0032 - acc: 0. - ETA: 1:02 - loss: 0.0032 - acc: 0.9 - ETA: 1:02 - loss: 0.0031 - acc: 0.999 - ETA: 1:02 - loss: 0.0031 -  - ETA: 1:01 -  - ETA: 38s - loss: 0.00 - ETA: 37s - loss: 0.0046 - acc: 0. - E - ETA: 29s - loss: 0.0042 - acc: 0. - ETA: 29s - loss: 0.0042 - a - ETA:  - ETA - ETA: 24s - loss: 0.0041 - acc: 0.99 - ETA: 24s - loss: 0.0041 - - ETA: 23s - loss: 0.00 - E - ETA: 7s - loss: 0.0043 - acc: 0.998 - ETA: 7s - loss: 0. - ETA: 5s - loss: 0.0043 - acc: 0.998 - ETA: 5s - loss: 0.0043 - acc: 0 - ETA: 5s - loss: - ETA: 3s - loss: 0.0043 - acc: 0.998 - ETA: 3s - loss: 0.0043 - a - ETA: 2s - loss: 0.0042 - acc: 0. - ETA: 1s - los\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 89s 1ms/step - loss: 0.0055 - acc: 0.9984TA: 1:27 - loss: 0.0085 - acc: - ETA: 1:26 - loss: 0.0067 - acc: 0.99 - ETA: 1:25 - loss: 0.0063 - ac - ETA: 1:24 - loss: 0.0059 - acc: 0. - ETA: 1:24 - loss: 0.0057 - acc: 0.99 - ETA: 1:24 - loss: 0.0059 - acc:  - ETA: 1:24 - loss: 0.0059 - a - ETA: 1:23 - loss: 0.0060 -  - ETA: 1:23 - loss: 0.0 - ETA: 1:21 - loss: 0.0076 - acc: 0.996 - ETA: 1:21 - loss: 0.0076 - ac - ETA: 1:20 - loss: 0.0074 - acc: 0 - ETA: 1:20 - loss: 0.0071 -  - ETA: 1:19 - loss: 0.0070 - acc: 0 - ETA: 1:18 - loss: 0.0069 -  - ETA: 1: - ETA: 1:15 - - ETA: 1:12 - loss: 0.0055 - - ETA: 1:11 - loss: 0.0054 - acc: 0.997 - ETA: 1:11 - loss: 0.0055 - - ETA: 1:07 - loss - ETA: 1:05 - loss: 0.0048 - ac - ETA: 1:04 - loss: 0.0047 - acc: - ETA: 1:03 - loss: 0.0046 - acc: 0. - ETA: 1:03 - loss: 0.0045 - acc:  - ETA: 1:03 - loss: 0.0045 - acc: 0. - ETA: 1:02 - loss: 0.0047  - ETA: 1:01 - loss: 0.0047 - acc: 0.99 - ETA: 1:01 - loss: 0.0047 - acc: - ETA: 1:00 - loss:  - - ETA: 57s - loss: 0.0049 - ETA: 57s - loss: 0.00 - ETA: 56s - loss: 0.0057 - acc:  - ETA - ETA: 52s - loss: 0.0061 - - E - ETA: 43s - loss: 0.0056 - - ETA: 43s - loss: 0.0056 - acc: 0.99 - ETA - ETA: 39s - loss: 0.0053 - acc: 0. - ETA: 39s - loss: 0.0053 - acc: 0.99 - ETA: 39s - loss: 0.0053 - acc - ETA: 39s - loss: 0. - ETA: 38s - loss:  - ETA: 37s - loss: 0.0052 - acc - ETA: 36s - loss: 0.0052 - acc: 0.99 - ETA: 36s -  - ETA: 35s - loss: 0.0054 - acc - ETA: 33s - loss: 0.0059 - ETA: 32 - ETA: 31s - loss: 0. - ETA - ETA: 29s - loss: 0.0058 - a - ETA:  - ETA: 27s - loss:  - ETA: 26s - loss: 0.0058 - - ETA:  - ETA: 22s - loss: 0.0057 - acc - ETA: 22s - loss - ETA: 21s - loss: 0.0057 - - ETA: 20s - loss: 0. - ETA: 19s - lo - ETA: 11s - loss: 0. - ETA: 11s - loss: 0.0058 - acc - ETA: 10s  - ETA: 8s - loss: 0.0059 - ETA: 7s - loss: 0.0058 - acc: 0.99 - ETA: 7s - loss: 0.0058 - acc: - ETA: 6s - loss: 0.0058 - acc: 0.99 - ETA: 6s - loss: 0.0058 - acc: 0.99 - ETA: 6s - loss: 0.0058 - - ETA: 5s - loss: 0.0058 -  - ETA: 4s - loss: - ETA: 2s - loss: 0.0056 - acc: - ETA: 2s - loss: 0.0056 - acc: 0.9 - ETA: 1s - loss: 0.0056 - acc: 0.998 - ETA: 1s - loss: 0.0056 - acc - ETA: 0s - loss: 0.0055 - acc: 0.998 - ETA: 0s - loss: 0.0055 - acc: 0.99 - ETA: 0s - loss: 0.0055 - acc:  - ETA: 0s - loss: 0.0055 - acc: 0.998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1468fbf00b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 562us/step\n",
      "Loss: 0.05220924971981804\n",
      "Accuracy: 98.61%\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "loss, accuracy = model.evaluate(x_test,y_test)\n",
    "print('Loss: '+str(loss))\n",
    "print('Accuracy: '+str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
