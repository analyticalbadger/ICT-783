{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fruit Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Sheldon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Sheldon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Sheldon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Sheldon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Sheldon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Sheldon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"fruits-360/Training/\"\n",
    "directory2 = \"fruits-360/Test/\"\n",
    "classes = [\"Apple Golden 1\",\"Avocado\",\"Banana\",\"Cherry 1\",\"Cocos\",\"Kiwi\",\"Lemon\",\"Mango\",\"Orange\"]\n",
    "\n",
    "all_arrays = []\n",
    "img_size = 100\n",
    "for i in classes:\n",
    "    path = os.path.join(directory,i)\n",
    "    class_num = classes.index(i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "        img_array = cv2.resize(img_array,(img_size,img_size))\n",
    "        all_arrays.append([img_array,class_num])\n",
    "\n",
    "all_arrays2 = []\n",
    "img_size = 100\n",
    "for i in classes:\n",
    "    path = os.path.join(directory2,i)\n",
    "    class_num2 = classes.index(i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array2 = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "        img_array2 = cv2.resize(img_array2,(img_size,img_size))\n",
    "        all_arrays2.append([img_array2,class_num2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_array_train=[]\n",
    "for features,label in all_arrays:\n",
    "    fruits_array_train.append(features)\n",
    "\n",
    "location = [[1,500,1150],[1500,2000,2500],[3000,3500,4000]]\n",
    "fruit_names = [\"Apple\",\"Avocado\",\"Banana\",\"Cherry\",\"Cocos\",\"Kiwi\",\"Lemon\",\"Mango\",\"Orange\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_arrays)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "for features,label in all_arrays:\n",
    "    x_train.append(features)\n",
    "    y_train.append(label)\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "random.shuffle(all_arrays2)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "for features,label in all_arrays2:\n",
    "    x_test.append(features)\n",
    "    y_test.append(label)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train=  (4306, 100, 100, 1)\n",
      "shape of x_test=   (1445, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Normalization and reshaping\n",
    "x_train = x_train.reshape(-1,img_size,img_size,1)\n",
    "x_train = x_train/255\n",
    "x_test = x_test.reshape(-1,img_size,img_size,1)\n",
    "x_test = x_test/255\n",
    "print(\"shape of x_train= \",x_train.shape)\n",
    "print(\"shape of x_test=  \",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes=9)\n",
    "y_test = to_categorical(y_test,num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sheldon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Sheldon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=(2,2),padding='same',input_shape=(100,100,1),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=32,kernel_size=(2,2),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=64,kernel_size=(2,2),padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=64,kernel_size=(2,2),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=150,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(units=9,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               1382550   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 1359      \n",
      "=================================================================\n",
      "Total params: 1,410,773\n",
      "Trainable params: 1,410,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sheldon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "3444/3444 [==============================] - 56s 16ms/step - loss: 0.7991 - acc: 0.7195\n",
      "Epoch 2/10\n",
      "3444/3444 [==============================] - 54s 16ms/step - loss: 0.1359 - acc: 0.9556\n",
      "Epoch 3/10\n",
      "3444/3444 [==============================] - 55s 16ms/step - loss: 0.0590 - acc: 0.9820\n",
      "Epoch 4/10\n",
      "3444/3444 [==============================] - 55s 16ms/step - loss: 0.0414 - acc: 0.9878\n",
      "Epoch 5/10\n",
      "3444/3444 [==============================] - 54s 16ms/step - loss: 0.0223 - acc: 0.9930\n",
      "Epoch 6/10\n",
      "3444/3444 [==============================] - 55s 16ms/step - loss: 0.0289 - acc: 0.9942\n",
      "Epoch 7/10\n",
      "3444/3444 [==============================] - 55s 16ms/step - loss: 0.0227 - acc: 0.9942\n",
      "Epoch 8/10\n",
      "3444/3444 [==============================] - 55s 16ms/step - loss: 0.0237 - acc: 0.9942\n",
      "Epoch 9/10\n",
      "3444/3444 [==============================] - 55s 16ms/step - loss: 0.0223 - acc: 0.9959\n",
      "Epoch 10/10\n",
      "3444/3444 [==============================] - 56s 16ms/step - loss: 0.0198 - acc: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20780f65630>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "#model.fit(x_train,y_train,epochs=30,batch_size=32)\n",
    "# Taking too long to run, cutting back to 10 epochs\n",
    "model.fit(x_train,y_train,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445/1445 [==============================] - 12s 8ms/step\n",
      "Loss: 0.07640891293583009\n",
      "Accuracy: 98.4083044982699%\n",
      "[[137   0   0   0   0   0  23   0   0]\n",
      " [  0 143   0   0   0   0   0   0   0]\n",
      " [  0   0 166   0   0   0   0   0   0]\n",
      " [  0   0   0 164   0   0   0   0   0]\n",
      " [  0   0   0   0 166   0   0   0   0]\n",
      " [  0   0   0   0   0 156   0   0   0]\n",
      " [  0   0   0   0   0   0 164   0   0]\n",
      " [  0   0   0   0   0   0   0 166   0]\n",
      " [  0   0   0   0   0   0   0   0 160]]\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "loss, accuracy = model.evaluate(x_test,y_test)\n",
    "print('Loss: '+str(loss))\n",
    "print('Accuracy: '+str(accuracy*100)+'%')\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = (y_pred>0.5)\n",
    "confusion_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
